x-airflow-common: &airflow-common
  build:
    context: ./airflow
  env_file:
    - .env
  environment:
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "false"
    AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    AIRFLOW__CORE__FERNET_KEY: ${FERNET_KEY}
    AIRFLOW__WEBSERVER__SECRET_KEY: ${SECRET_KEY}
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./scala-etl/target/scala-2.12:/opt/etl            # JARs accessible inside container
  depends_on:
    - postgres
    - spark

services:

  postgres:
    image: postgres:13
    env_file:
      - .env
    environment:
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data

  spark:
    image: apache/spark:3.5.0
    container_name: spark
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    volumes:
      - ./scala-etl/target/scala-2.12:/opt/etl
    ports:
      - "7077:7077"
      - "8081:8080"

  airflow-init:
    <<: *airflow-common
    command: >
      bash -c "
        airflow db init &&
        airflow users create --username ${AIRFLOW_ADMIN_USERNAME} --password ${AIRFLOW_ADMIN_PASSWORD} --firstname ${AIRFLOW_ADMIN_FIRSTNAME} --lastname ${AIRFLOW_ADMIN_LASTNAME} --role Admin --email ${AIRFLOW_ADMIN_EMAIL}
      "
    restart: "no"

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "8080:8080"

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler

volumes:
  postgres-db-volume:
